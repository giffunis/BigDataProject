<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>BigData - proyecto</title>
            <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only],
.vscode-high-contrast:not(.vscode-high-contrast-light) img[src$=\#gh-light-mode-only],
.vscode-high-contrast-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
            
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
<style>
:root {
  --color-note: #0969da;
  --color-tip: #1a7f37;
  --color-warning: #9a6700;
  --color-severe: #bc4c00;
  --color-caution: #d1242f;
  --color-important: #8250df;
}

</style>
<style>
@media (prefers-color-scheme: dark) {
  :root {
    --color-note: #2f81f7;
    --color-tip: #3fb950;
    --color-warning: #d29922;
    --color-severe: #db6d28;
    --color-caution: #f85149;
    --color-important: #a371f7;
  }
}

</style>
<style>
.markdown-alert {
  padding: 0.5rem 1rem;
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid #888;
}

.markdown-alert>:first-child {
  margin-top: 0
}

.markdown-alert>:last-child {
  margin-bottom: 0
}

.markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1
}

.markdown-alert .markdown-alert-title .octicon {
  margin-right: 0.5rem;
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-alert.markdown-alert-note {
  border-left-color: var(--color-note);
}

.markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-note);
}

.markdown-alert.markdown-alert-important {
  border-left-color: var(--color-important);
}

.markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-important);
}

.markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-warning);
}

.markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-warning);
}

.markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-tip);
}

.markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-tip);
}

.markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-caution);
}

.markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-caution);
}

</style>
        
        </head>
        <body class="vscode-body vscode-light">
            <!-- title: BigData - proyecto -->
<h1 id="bigdata---proyecto-parte-1">BigData - Proyecto parte 1</h1>
<p>Parte 1
Proyecto asignatura BigData.<br>
Máster Universitario en Ingeniería Informática - Universidad Pablo de Olavide</p>
<h2 id="ejecución-del-laboratorio-de-la-parte-1">Ejecución del laboratorio de la parte 1</h2>
<p>Escribimos las siguientes líneas en un fichero <code>compose.yaml</code>, cambiando el mapeo del volumen <code>data</code> por el de su equipo:</p>
<pre><code>services:
hbase-pseudo:
    image: jsgifbec/custom-hbase-pseudo:latest
    container_name: hbase-pseudo
    hostname: hbase-pseudo
    volumes:
    - /media/SHARED/repositories/BigDataProject/docker/services/hbase-pseudo/data:/data
    ports:
    - 2181:2181
    - 8080:8080
    - 8085:8085
    - 9090:9090
    - 9095:9095
    - 16000:16000 # master
    - 16010:16010 # master-ui
    - 16201-16210:16201-16210 # region servers
    - 16301-16310:16301-16310 # region servers - ui
    restart: unless-stopped
</code></pre>
<p>y, ejecutamos en el mismo directorio del fichero:</p>
<pre><code>docker compose up -d
</code></pre>
<p>Abrimos una consola bash en el contenedor mediante:</p>
<pre><code>docker exec -it hbase-pseudo bash
</code></pre>
<p>Los comandos son explicados en el <a href="#3-invocaci%C3%B3n-de-las-herramientas-de-carga-y-extracci%C3%B3n">punto 3</a> de este documento.</p>
<h2 id="enlace-del-vídeo">Enlace del vídeo</h2>
<p><a href="https://youtu.be/yg8LbI_Mag0">Vídeo BigData parte 1</a></p>
<h2 id="requisitos-del-trabajo-final---parte1">Requisitos del trabajo final - parte1</h2>
<p><strong>Requisitos obligatorios</strong></p>
<ul>
<li><a href="#1-justificaci%C3%B3n-de-la-estructura-de-datos">1. Justificación de la estructura de datos</a>.</li>
<li><a href="#2-detalle-de-las-herramientas-desarrolladas">2. Detalle de las herramientas desarrolladas</a>.</li>
<li><a href="#3-invocaci%C3%B3n-de-las-herramientas-de-carga-y-extracci%C3%B3n">3. Invocación de las herramientas de carga y extracción</a>.</li>
<li><a href="#4-scripts-de-creaci%C3%B3n-de-tablas-y-limpieza">4. Scripts de creación de tablas y limpieza</a>.</li>
<li><a href="#5-c%C3%B3digo-fuente-de-las-herramientas-desarrolladas">5. Código fuente de las herramientas desarrolladas</a>.</li>
</ul>
<h3 id="1-justificación-de-la-estructura-de-datos">1. Justificación de la estructura de datos</h3>
<h4 id="11-rowid">1.1 RowId</h4>
<p>La rowId es formada de la siguiente manera:</p>
<pre><code>private static String GetRowKey(SynteticData mr) {
    int bucket = computeBucket(mr.getSensorAsString() + mr.getDayAsString(), Commons.N_LOCAL_REGION_SERVERS);
    String rowKey = bucket + &quot;#&quot; + mr.getSensorAsString() + &quot;#&quot; + mr.getDayAsString();
    return rowKey;
}

// Es decir, hash + &quot;#&quot; + sensorId + &quot;#&quot; + day
</code></pre>
<p>De esta forma la rowId será igual para todos las lecturas de un sensor en un mismo día.</p>
<p>El hash, se calcula de la siguiente manera:</p>
<pre><code>private static int computeBucket(String key, int buckets) {
    int rawHash = key.hashCode();
    int positiveHash = rawHash &amp; Integer.MAX_VALUE;
    return positiveHash % (buckets);
}
</code></pre>
<p>Siendo <code>buckets</code> el número de servidores de región, 3. Ese hash devolverá valores [0, N_LOCAL_REGION_SERVERS - 1]. Asegurando de esta manera, una distribución equitativa entre las regiones porque el número de divisiones (splits), en el <code>createTable</code> también está condicionado por el número de regiones:</p>
<pre><code>byte[][] splits = new byte[Commons.N_LOCAL_REGION_SERVERS - 1][];
for (int i = 1; i &lt; Commons.N_LOCAL_REGION_SERVERS; i++) {
    splits[i - 1] = Bytes.toBytes(Integer.toString(i));
}
</code></pre>
<p>Para 3 servidores de región:</p>
<ul>
<li>Región 1: desde el inicio hasta <code>1</code></li>
<li>Región 2: <code>1</code> → <code>2</code></li>
<li>Región 3: <code>2</code> → desde <code>2</code> en adelante</li>
</ul>
<h4 id="12-familia-de-columnas-y-columnas">1.2 Familia de columnas y columnas</h4>
<p>La estructura de las familias de columna escogida es la siguiente:</p>
<table>
<thead>
<tr>
<th>general</th>
<th>measure1</th>
<th>measure2</th>
<th></th>
<th>measureC</th>
</tr>
</thead>
<tbody>
<tr>
<td>sensorId = 1DGXXXX1, day = 2013-12-01</td>
<td>00:00 =&gt; valor_s1m1_00:00</td>
<td>00:00 =&gt; valor_s1m2_00:00</td>
<td>...</td>
<td>00:00 =&gt; valor_s1mC_00:00</td>
</tr>
<tr>
<td></td>
<td>00:10 =&gt; valor_s1m1_00:10</td>
<td>00:10 =&gt; valor_s1m2_00:10</td>
<td>...</td>
<td>00:10 =&gt; valor_s1mC_00:10</td>
</tr>
<tr>
<td></td>
<td>00:20 =&gt; valor_s1m1_00:20</td>
<td>00:20 =&gt; valor_s1m2_00:00</td>
<td>...</td>
<td>00:20 =&gt; valor_s1mC_00:20</td>
</tr>
<tr>
<td></td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>sensorId = 1DGXXXX2, day = 2013-12-01</td>
<td>00:00 =&gt; valor_s2m1_00:00</td>
<td>00:00 =&gt; valor_s2m2_00:00</td>
<td>...</td>
<td>00:00 =&gt; valor_s2mC_00:00</td>
</tr>
<tr>
<td></td>
<td>00:10 =&gt; valor_s2m1_00:10</td>
<td>00:10 =&gt; valor_s2m2_00:10</td>
<td>...</td>
<td>00:10 =&gt; valor_s2mC_00:10</td>
</tr>
<tr>
<td></td>
<td>00:20 =&gt; valor_s2m1_00:20</td>
<td>00:20 =&gt; valor_s2m2_00:00</td>
<td>...</td>
<td>00:20 =&gt; valor_s2mC_00:20</td>
</tr>
</tbody>
</table>
<p>De esta manera, todas las medidas tomadas por el lector1 del sensor 1DGXXXXX, el día 2013-12-01, es almacenada en una sola familia de columna para cada rowId. Siendo necesario leer tan solo dos familias de columnas para extraer toda la información que necesitamos, la general (contiene el sensorId y el día) y la familia de columna correspondiente al C introducido.</p>
<h4 id="13-problemas-encontrados">1.3 Problemas encontrados.</h4>
<p>Esta estrucuta y, generación de rowId, hace necesario ordenar las filas extraidas. Primero por la columna general:sensorId y luego por general:day. Pero, no hace lecturas innecesarias.</p>
<h3 id="2-detalle-de-las-herramientas-desarrolladas">2. Detalle de las herramientas desarrolladas</h3>
<p>Las herramientas están definidas en dos subcomandos de la aplicación:</p>
<ol>
<li>
<p>load-table</p>
<p>@Command(name = &quot;load-table&quot;, description = &quot;Herramienta de carga&quot;)
class LoadTable implements Runnable {
@Option(names = {&quot;-f&quot;, &quot;--file&quot;}, required = true, description = &quot;Archivo CSV a cargar&quot;)
String file;</p>
<pre><code> @Option(names = {&quot;--factor-c&quot;}, required = true, description = &quot;Factor de multiplicación de columna&quot;)
 int factorC;
 
 @Option(names = {&quot;--factor-f&quot;}, required = true, description = &quot;Factor de multiplicación de fila&quot;)
 int factorF;

 public void run() {
     
     try {
         // Borramos todas las tablas
         dropTables();
             
         // Creamos la estructura de la tabla
         HTableDescriptor tableDescriptor = defineTable(factorC);
         createTable(tableDescriptor);
             
         // Leemos el fichero y aplicamos el bootstrapping
         List&lt;SynteticData&gt; synteticData = generateSyntheticReadings(readCsv(file),factorF);
             
         // Insertamos en Hbase 
         insertDataIntoHbase(tableDescriptor, synteticData);
         
     } catch (Exception e) {
         System.out.println(e.toString());
     }
     
 }
 ...
</code></pre>
<p>}</p>
</li>
<li>
<p>retrieve-table</p>
<p>@Command(name = &quot;retrieve-data&quot;, description = &quot;Herramienta de extracción&quot;)
class RetrieveData implements Runnable {
@Option(names = {&quot;-c&quot;, &quot;--column&quot;}, required = true, description = &quot;Columna de extración&quot;)
int retriveColumn;</p>
<pre><code> @Option(names = {&quot;-r&quot;, &quot;--row&quot;}, required = true, description = &quot;Fila de extración&quot;)
 int retriveRow;

 @Option(names = {&quot;-o&quot;, &quot;--output&quot;}, required = true, description = &quot;Archivo de salida&quot;)
 String output;

 public void run() {
     try {
         String cF = String.format(&quot;%s%d&quot;, Commons.CF_MEASUREX, retriveColumn);
         String fId = String.format(&quot;%dDG&quot;, retriveRow);
         writeCsv(output, generateHeader(), getRowsBySensorPrefix(fId, cF));
         
     } catch (Exception e) {
         System.out.println(e.toString());
     }
     
 }
 ...
</code></pre>
<p>}</p>
</li>
</ol>
<h3 id="3-invocación-de-las-herramientas-de-carga-y-extracción">3. Invocación de las herramientas de carga y extracción</h3>
<h4 id="31-invocación-de-la-herramienta-de-carga">3.1 Invocación de la herramienta de carga</h4>
<p>El uso es el siguiente:</p>
<pre><code>Usage: BigData load-table -f=&lt;file&gt; --factor-c=&lt;factorC&gt; --factor-f=&lt;factorF&gt;
Herramienta de carga
    -f, --file=&lt;file&gt;           Archivo CSV a cargar
    --factor-c=&lt;factorC&gt;        Factor de multiplicación de columna
    --factor-f=&lt;factorF&gt;        Factor de multiplicación de fila
</code></pre>
<p>Ejemplo:</p>
<pre><code>bigdata load-table --file SET-dec-2013.csv --factor-f 5 --factor-c 5
</code></pre>
<h4 id="32-invocación-de-la-herramienta-de-extracción">3.2 Invocación de la herramienta de extracción</h4>
<p>El uso es el siguiente:</p>
<pre><code>Usage: BigData retrieve-data -c=&lt;retriveColumn&gt; -o=&lt;output&gt; -r=&lt;retriveRow&gt;
Herramienta de extracción
-c, --column=&lt;retriveColumn&gt;    Columna de extración
-o, --output=&lt;output&gt;           Archivo de salida
-r, --row=&lt;retriveRow&gt;          Fila de extración
</code></pre>
<p>Ejemplo:</p>
<pre><code>bigdata retrieve-data -o salida.csv -r 3 -c 3
</code></pre>
<h3 id="4-scripts-de-creación-de-tablas-y-limpieza">4. Scripts de creación de tablas y limpieza</h3>
<p>Los scripts de creación y eliminación de la tabla están integrados en la herramienta de carga. El orden de ejecución dentro de la misma es el siguiente:</p>
<pre><code>public void run() {

        // Borramos todas las tablas
        dropTables();
            
        // Creamos la estructura de la tabla
        HTableDescriptor tableDescriptor = defineTable(factorC);
        createTable(tableDescriptor);
            
        ...
}
</code></pre>
<h4 id="41-script-de-creación-de-la-tabla">4.1 Script de creación de la tabla</h4>
<p>Para crear la tabla, primero hay que definirla. Esto se realiza mediante el método <code>defineTable</code> que recibe cómo parámetro el número de medidas de los sensores (ligado al factor de multiplicación de columnas):</p>
<pre><code>private static HTableDescriptor defineTable(int nMeasuresBySensor) {
    HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(Commons.TABLE_NAME));

    tableDescriptor.addFamily(new HColumnDescriptor(Commons.CF_GENERAL));

    for (int m = 1; m &lt;= nMeasuresBySensor; m++) {
        tableDescriptor.addFamily(new HColumnDescriptor(String.format(&quot;%s%d&quot;, Commons.CF_MEASUREX, m)));
    }
    System.out.println(&quot;Definida la nueva estructura de la tabla&quot;);
    return tableDescriptor;
}
</code></pre>
<p>Una vez creado el objeto que define la tabla, se lo pasamos al método <code>createTable</code> quien define las regiones y crea la tabla:</p>
<pre><code>private static void createTable(HTableDescriptor tableDescriptor) throws IOException {
    try (Connection connection = HBaseConnector.getConnection()) {
        Admin admin = connection.getAdmin();

        byte[][] splits = new byte[Commons.N_LOCAL_REGION_SERVERS - 1][];
        for (int i = 1; i &lt; Commons.N_LOCAL_REGION_SERVERS; i++) {
            splits[i - 1] = Bytes.toBytes(Integer.toString(i));
        }

        admin.createTable(tableDescriptor, splits);
    }
    System.out.println(&quot;Creada la nueva tabla&quot;);
}
</code></pre>
<h4 id="42-script-de-limpieza">4.2 Script de limpieza</h4>
<p>El script de limpieza está integrado en la herramienta de carga. Su funcionamiento es el siguiente:</p>
<ol>
<li>Deshabilita la tabla.</li>
<li>Elimina la tabla.</li>
</ol>
<p>El código es el siguiente:</p>
<pre><code>private static void dropTables() throws IOException {
    try (Connection connection = HBaseConnector.getConnection()) {
        Admin admin = connection.getAdmin();

        for (TableName table : admin.listTableNames()) {
            if(!admin.isTableDisabled(table))
                admin.disableTable(table);
            admin.deleteTable(table);
        }
    }
    System.out.println(&quot;Eliminadas las tablas existentes&quot;);
}
</code></pre>
<h3 id="5-código-fuente-de-las-herramientas-desarrolladas">5. Código fuente de las herramientas desarrolladas</h3>
<p>El código fuente se encuentra adjunto a este documento y publicado en github:</p>
<p><a href="https://github.com/giffunis/BigDataProject/tree/parte1">Repositorio en Github - tag:parte1</a></p>

            
            
        </body>
        </html>